# PIPELINE DEFINITION
# Name: docling-convert-pipeline
# Description: Converts audio recordings to text using Docling ASR and generates embeddings
# Inputs:
#    audio_filenames: str [Default: 'RAG_use_cases.wav, RAG_customers.wav, RAG_benefits.m4a, RAG_vs_Regular_LLM_Output.m4a']
#    base_url: str [Default: 'https://raw.githubusercontent.com/opendatahub-io/rag/main/demos/testing-data/audio-speech']
#    embed_model_id: str [Default: 'ibm-granite/granite-embedding-125m-english']
#    max_tokens: int [Default: 512.0]
#    num_workers: int [Default: 1.0]
#    service_url: str [Default: 'http://lsd-llama-milvus-service:8321']
#    use_gpu: bool [Default: True]
#    vector_db_id: str [Default: 'asr-vector-db']
components:
  comp-condition-3:
    dag:
      tasks:
        docling-convert-and-ingest-audio:
          cachingOptions: {}
          componentRef:
            name: comp-docling-convert-and-ingest-audio
          inputs:
            artifacts:
              input_path:
                componentInputArtifact: pipelinechannel--import-audio-files-output_path
            parameters:
              audio_split:
                componentInputParameter: pipelinechannel--create-audio-splits-Output-loop-item
              embed_model_id:
                componentInputParameter: pipelinechannel--embed_model_id
              max_tokens:
                componentInputParameter: pipelinechannel--max_tokens
              service_url:
                componentInputParameter: pipelinechannel--service_url
              vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          taskInfo:
            name: docling-convert-and-ingest-audio
    inputDefinitions:
      artifacts:
        pipelinechannel--import-audio-files-output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--create-audio-splits-Output-loop-item:
          parameterType: LIST
        pipelinechannel--embed_model_id:
          parameterType: STRING
        pipelinechannel--max_tokens:
          parameterType: NUMBER_INTEGER
        pipelinechannel--service_url:
          parameterType: STRING
        pipelinechannel--use_gpu:
          parameterType: BOOLEAN
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-condition-4:
    dag:
      tasks:
        docling-convert-and-ingest-audio-2:
          cachingOptions: {}
          componentRef:
            name: comp-docling-convert-and-ingest-audio-2
          inputs:
            artifacts:
              input_path:
                componentInputArtifact: pipelinechannel--import-audio-files-output_path
            parameters:
              audio_split:
                componentInputParameter: pipelinechannel--create-audio-splits-Output-loop-item
              embed_model_id:
                componentInputParameter: pipelinechannel--embed_model_id
              max_tokens:
                componentInputParameter: pipelinechannel--max_tokens
              service_url:
                componentInputParameter: pipelinechannel--service_url
              vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          taskInfo:
            name: docling-convert-and-ingest-audio-2
    inputDefinitions:
      artifacts:
        pipelinechannel--import-audio-files-output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--create-audio-splits-Output-loop-item:
          parameterType: LIST
        pipelinechannel--embed_model_id:
          parameterType: STRING
        pipelinechannel--max_tokens:
          parameterType: NUMBER_INTEGER
        pipelinechannel--service_url:
          parameterType: STRING
        pipelinechannel--use_gpu:
          parameterType: BOOLEAN
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-condition-branches-2:
    dag:
      tasks:
        condition-3:
          componentRef:
            name: comp-condition-3
          inputs:
            artifacts:
              pipelinechannel--import-audio-files-output_path:
                componentInputArtifact: pipelinechannel--import-audio-files-output_path
            parameters:
              pipelinechannel--create-audio-splits-Output-loop-item:
                componentInputParameter: pipelinechannel--create-audio-splits-Output-loop-item
              pipelinechannel--embed_model_id:
                componentInputParameter: pipelinechannel--embed_model_id
              pipelinechannel--max_tokens:
                componentInputParameter: pipelinechannel--max_tokens
              pipelinechannel--service_url:
                componentInputParameter: pipelinechannel--service_url
              pipelinechannel--use_gpu:
                componentInputParameter: pipelinechannel--use_gpu
              pipelinechannel--vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          taskInfo:
            name: condition-3
          triggerPolicy:
            condition: inputs.parameter_values['pipelinechannel--use_gpu'] == true
        condition-4:
          componentRef:
            name: comp-condition-4
          inputs:
            artifacts:
              pipelinechannel--import-audio-files-output_path:
                componentInputArtifact: pipelinechannel--import-audio-files-output_path
            parameters:
              pipelinechannel--create-audio-splits-Output-loop-item:
                componentInputParameter: pipelinechannel--create-audio-splits-Output-loop-item
              pipelinechannel--embed_model_id:
                componentInputParameter: pipelinechannel--embed_model_id
              pipelinechannel--max_tokens:
                componentInputParameter: pipelinechannel--max_tokens
              pipelinechannel--service_url:
                componentInputParameter: pipelinechannel--service_url
              pipelinechannel--use_gpu:
                componentInputParameter: pipelinechannel--use_gpu
              pipelinechannel--vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          taskInfo:
            name: condition-4
          triggerPolicy:
            condition: '!(inputs.parameter_values[''pipelinechannel--use_gpu''] ==
              true)'
    inputDefinitions:
      artifacts:
        pipelinechannel--import-audio-files-output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--create-audio-splits-Output-loop-item:
          parameterType: LIST
        pipelinechannel--embed_model_id:
          parameterType: STRING
        pipelinechannel--max_tokens:
          parameterType: NUMBER_INTEGER
        pipelinechannel--service_url:
          parameterType: STRING
        pipelinechannel--use_gpu:
          parameterType: BOOLEAN
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-create-audio-splits:
    executorLabel: exec-create-audio-splits
    inputDefinitions:
      artifacts:
        input_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        num_splits:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      parameters:
        Output:
          parameterType: LIST
  comp-docling-convert-and-ingest-audio:
    executorLabel: exec-docling-convert-and-ingest-audio
    inputDefinitions:
      artifacts:
        input_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        audio_split:
          parameterType: LIST
        embed_model_id:
          parameterType: STRING
        max_tokens:
          parameterType: NUMBER_INTEGER
        service_url:
          parameterType: STRING
        vector_db_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-docling-convert-and-ingest-audio-2:
    executorLabel: exec-docling-convert-and-ingest-audio-2
    inputDefinitions:
      artifacts:
        input_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        audio_split:
          parameterType: LIST
        embed_model_id:
          parameterType: STRING
        max_tokens:
          parameterType: NUMBER_INTEGER
        service_url:
          parameterType: STRING
        vector_db_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-for-loop-1:
    dag:
      tasks:
        condition-branches-2:
          componentRef:
            name: comp-condition-branches-2
          inputs:
            artifacts:
              pipelinechannel--import-audio-files-output_path:
                componentInputArtifact: pipelinechannel--import-audio-files-output_path
            parameters:
              pipelinechannel--create-audio-splits-Output-loop-item:
                componentInputParameter: pipelinechannel--create-audio-splits-Output-loop-item
              pipelinechannel--embed_model_id:
                componentInputParameter: pipelinechannel--embed_model_id
              pipelinechannel--max_tokens:
                componentInputParameter: pipelinechannel--max_tokens
              pipelinechannel--service_url:
                componentInputParameter: pipelinechannel--service_url
              pipelinechannel--use_gpu:
                componentInputParameter: pipelinechannel--use_gpu
              pipelinechannel--vector_db_id:
                componentInputParameter: pipelinechannel--vector_db_id
          taskInfo:
            name: condition-branches-2
    inputDefinitions:
      artifacts:
        pipelinechannel--import-audio-files-output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--create-audio-splits-Output:
          parameterType: LIST
        pipelinechannel--create-audio-splits-Output-loop-item:
          parameterType: LIST
        pipelinechannel--embed_model_id:
          parameterType: STRING
        pipelinechannel--max_tokens:
          parameterType: NUMBER_INTEGER
        pipelinechannel--service_url:
          parameterType: STRING
        pipelinechannel--use_gpu:
          parameterType: BOOLEAN
        pipelinechannel--vector_db_id:
          parameterType: STRING
  comp-import-audio-files:
    executorLabel: exec-import-audio-files
    inputDefinitions:
      parameters:
        audio_filenames:
          parameterType: STRING
        base_url:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-register-vector-db:
    executorLabel: exec-register-vector-db
    inputDefinitions:
      parameters:
        embed_model_id:
          parameterType: STRING
        service_url:
          parameterType: STRING
        vector_db_id:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-create-audio-splits:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - create_audio_splits
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef create_audio_splits(\n    input_path: dsl.InputPath(\"input-recordings\"\
          ),\n    num_splits: int,\n) -> List[List[str]]:\n    import pathlib\n\n\
          \    # Split our entire directory of audio files into n batches, where n\
          \ == num_splits\n    # Support common audio formats\n    audio_extensions\
          \ = [\"*.wav\", \"*.mp3\", \"*.m4a\", \"*.flac\", \"*.ogg\", \"*.aac\"]\n\
          \    all_audio = []\n\n    input_dir = pathlib.Path(input_path)\n    for\
          \ ext in audio_extensions:\n        all_audio.extend([path.name for path\
          \ in input_dir.glob(ext)])\n\n    splits = [\n        batch\n        for\
          \ batch in (all_audio[i::num_splits] for i in range(num_splits))\n     \
          \   if batch\n    ]\n    return splits or [[]]\n\n"
        image: registry.redhat.io/ubi9/python-312@sha256:e80ff3673c95b91f0dafdbe97afb261eab8244d7fd8b47e20ffcbcfee27fb168
    exec-docling-convert-and-ingest-audio:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - docling_convert_and_ingest_audio
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'docling' 'docling-core'\
          \ 'transformers' 'sentence-transformers' 'llama-stack' 'llama-stack-client'\
          \ 'pymilvus' 'fire' 'openai-whisper' 'torch' 'torchaudio' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef docling_convert_and_ingest_audio(\n    input_path: dsl.InputPath(\"\
          input-recordings\"),\n    audio_split: List[str],\n    output_path: dsl.OutputPath(\"\
          output-md\"),\n    embed_model_id: str,\n    max_tokens: int,\n    service_url:\
          \ str,\n    vector_db_id: str,\n):\n    import pathlib\n    import subprocess\n\
          \    import os\n\n    from docling.datamodel.pipeline_options_asr_model\
          \ import (\n        InlineAsrNativeWhisperOptions,\n        InferenceAsrFramework,\n\
          \    )\n\n    from docling.datamodel.base_models import ConversionStatus,\
          \ InputFormat\n    from docling.datamodel.document import ConversionResult\n\
          \    from docling.datamodel.pipeline_options import AsrPipelineOptions\n\
          \    from docling.document_converter import AudioFormatOption, DocumentConverter\n\
          \    from docling.pipeline.asr_pipeline import AsrPipeline\n    from docling_core.types.doc.document\
          \ import DoclingDocument\n\n    from transformers import AutoTokenizer\n\
          \    from sentence_transformers import SentenceTransformer\n    from docling_core.transforms.chunker.hybrid_chunker\
          \ import HybridChunker\n    import logging\n    from llama_stack_client\
          \ import LlamaStackClient\n    import uuid\n    import json\n\n    _log\
          \ = logging.getLogger(__name__)\n\n    # Install ffmpeg from https://ffmpeg.org/download.html#build-linux\n\
          \    def install_ffmpeg() -> None:\n        try:\n            # Check if\
          \ ffmpeg is already installed\n            subprocess.run([\"ffmpeg\", \"\
          -version\"], capture_output=True, check=True)\n            print(\"ffmpeg\
          \ is already installed\")\n            return\n        except (subprocess.CalledProcessError,\
          \ FileNotFoundError):\n            print(\"Installing ffmpeg...\")\n\n \
          \       try:\n\n            print(\"Package management restricted, downloading\
          \ static ffmpeg binary...\")\n\n            import urllib.request\n    \
          \        import stat\n            import pathlib\n            import shutil\n\
          \n            # Create temp directory\n            temp_dir = pathlib.Path(\"\
          /tmp/ffmpeg_install\")\n            temp_dir.mkdir(exist_ok=True)\n\n  \
          \          # Download static ffmpeg binary\n            ffmpeg_url = \"\
          https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz\"\
          \n            ffmpeg_archive = temp_dir / \"ffmpeg-static.tar.xz\"\n\n \
          \           print(f\"Downloading ffmpeg from {ffmpeg_url}\")\n         \
          \   urllib.request.urlretrieve(ffmpeg_url, ffmpeg_archive)\n\n         \
          \   print(\"Extracting ffmpeg archive...\")\n            subprocess.run(\n\
          \                [\"tar\", \"-xf\", str(ffmpeg_archive), \"-C\", str(temp_dir)],\n\
          \                check=True,\n                capture_output=True,\n   \
          \         )\n\n            ffmpeg_path_candidates = list(temp_dir.rglob(\"\
          ffmpeg\"))\n            if not ffmpeg_path_candidates:\n               \
          \ raise FileNotFoundError(\n                    \"Could not find 'ffmpeg'\
          \ executable in the extracted archive.\"\n                )\n\n        \
          \    ffmpeg_path = ffmpeg_path_candidates[0]\n\n            # Make executable\n\
          \            ffmpeg_path.chmod(\n                ffmpeg_path.stat().st_mode\
          \ | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH\n            )\n\n      \
          \      # Use a writable bin directory and add it to the PATH\n         \
          \   bin_dir = pathlib.Path(\"/tmp/bin\")\n            bin_dir.mkdir(exist_ok=True)\n\
          \            target_path = bin_dir / \"ffmpeg\"\n\n            # Move the\
          \ file to the target path\n            ffmpeg_path.rename(target_path)\n\
          \n            # Add to PATH environment variable\n            os.environ[\"\
          PATH\"] = f\"{str(bin_dir)}:{os.environ.get('PATH', '')}\"\n\n         \
          \   # Verify installation\n            subprocess.run(\n               \
          \ [str(target_path), \"-version\"], capture_output=True, check=True\n  \
          \          )\n            print(f\"Static ffmpeg binary installed to {target_path}\
          \ and added to PATH\")\n\n            # Clean up extraction directory\n\
          \            shutil.rmtree(temp_dir, ignore_errors=True)\n            return\n\
          \n        except Exception as e:\n            print(f\"Failed to install\
          \ ffmpeg: {e}\")\n            raise RuntimeError(\n                \"ffmpeg\
          \ installation failed. Audio processing requires ffmpeg.\"\n           \
          \ ) from e\n\n    # Convert audio files to WAV format that whisper can process\n\
          \    def convert_audio_to_wav(\n        input_audio_files: List[pathlib.Path],\n\
          \    ) -> Tuple[List[pathlib.Path], List[pathlib.Path]]:\n        processed_audio_files\
          \ = []\n        temp_files_to_cleanup = []\n\n        for audio_file in\
          \ input_audio_files:\n            if not audio_file.exists():\n        \
          \        print(f\"Skipping missing file: {audio_file}\")\n             \
          \   continue\n\n            # Check if file is already WAV\n           \
          \ if audio_file.suffix.lower() == \".wav\":\n                processed_audio_files.append(audio_file)\n\
          \                print(f\"Using WAV file directly: {audio_file.name}\")\n\
          \                continue\n\n            # Convert non-WAV files to WAV\
          \ format using ffmpeg\n            print(f\"Converting {audio_file.name}\
          \ to WAV format...\")\n            import tempfile\n\n            with tempfile.NamedTemporaryFile(\n\
          \                suffix=f\"_{audio_file.stem}.wav\", delete=False\n    \
          \        ) as tmp:\n                temp_wav = pathlib.Path(tmp.name)\n\n\
          \            try:\n                # Use ffmpeg to convert to WAV format\n\
          \                subprocess.run(\n                    [\n              \
          \          \"ffmpeg\",\n                        \"-i\",\n              \
          \          str(audio_file),\n                        \"-ar\",\n        \
          \                \"16000\",  # 16kHz sample rate (good for whisper)\n  \
          \                      \"-ac\",\n                        \"1\",  # mono\
          \ channel\n                        \"-c:a\",\n                        \"\
          pcm_s16le\",  # 16-bit PCM\n                        \"-y\",  # overwrite\
          \ output file\n                        str(temp_wav),\n                \
          \    ],\n                    check=True,\n                    capture_output=True,\n\
          \                )\n\n                processed_audio_files.append(temp_wav)\n\
          \                temp_files_to_cleanup.append(temp_wav)\n              \
          \  print(f\"Successfully converted {audio_file.name} to WAV format\")\n\n\
          \            except subprocess.CalledProcessError as e:\n              \
          \  print(f\"ffmpeg conversion failed for {audio_file.name}: {e}\")\n   \
          \             if e.stderr:\n                    print(f\"stderr: {e.stderr.decode()}\"\
          )\n                continue\n        return (processed_audio_files, temp_files_to_cleanup)\n\
          \n    # Clean up temporary files\n    def cleanup_temp_files(temp_files_to_cleanup:\
          \ List[pathlib.Path]) -> None:\n        for temp_file in temp_files_to_cleanup:\n\
          \            temp_file.unlink(missing_ok=True)\n            print(f\"Cleaned\
          \ up temporary file: {temp_file.name}\")\n\n    # Return a Docling DocumentConverter\
          \ configured for ASR with whisper_turbo model.\n    def get_asr_converter()\
          \ -> DocumentConverter:\n        \"\"\"Create a DocumentConverter configured\
          \ for ASR with whisper_turbo model.\"\"\"\n        whisper_turbo_asr_model\
          \ = InlineAsrNativeWhisperOptions(\n            repo_id=\"turbo\",\n   \
          \         inference_framework=InferenceAsrFramework.WHISPER,\n         \
          \   verbose=True,\n            timestamps=False,\n            word_timestamps=False,\n\
          \            temperature=0.0,\n            max_new_tokens=256,\n       \
          \     max_time_chunk=30.0,\n        )\n\n        pipeline_options = AsrPipelineOptions()\n\
          \        pipeline_options.asr_options = whisper_turbo_asr_model\n\n    \
          \    converter = DocumentConverter(\n            format_options={\n    \
          \            InputFormat.AUDIO: AudioFormatOption(\n                   \
          \ pipeline_cls=AsrPipeline,\n                    pipeline_options=pipeline_options,\n\
          \                )\n            }\n        )\n\n        return converter\n\
          \n    # ---- Embedding Helper functions ----\n    def setup_chunker_and_embedder(\n\
          \        embed_model_id: str, max_tokens: int\n    ) -> Tuple[SentenceTransformer,\
          \ HybridChunker]:\n        tokenizer = AutoTokenizer.from_pretrained(embed_model_id)\n\
          \        embedding_model = SentenceTransformer(embed_model_id)\n       \
          \ chunker = HybridChunker(\n            tokenizer=tokenizer, max_tokens=max_tokens,\
          \ merge_peers=True\n        )\n        return embedding_model, chunker\n\
          \n    def embed_text(text: str, embedding_model: SentenceTransformer) ->\
          \ list[float]:\n        return embedding_model.encode([text], normalize_embeddings=True).tolist()[0]\n\
          \n    def create_chunks_with_embeddings(\n        converted_data: DoclingDocument,\n\
          \        embedding_model: SentenceTransformer,\n        chunker: HybridChunker,\n\
          \        file_name: str,\n    ) -> List[Dict]:\n\n        chunks_with_embeddings\
          \ = []\n        for chunk in chunker.chunk(dl_doc=converted_data):\n   \
          \         raw_chunk = chunker.contextualize(chunk)\n            embedding\
          \ = embed_text(raw_chunk, embedding_model)\n            chunk_id = str(uuid.uuid4())\n\
          \            content_token_count = chunker.tokenizer.count_tokens(raw_chunk)\n\
          \n            # Prepare metadata object\n            metadata_obj = {\n\
          \                \"file_name\": file_name,\n                \"document_id\"\
          : chunk_id,\n                \"token_count\": content_token_count,\n   \
          \         }\n\n            metadata_str = json.dumps(metadata_obj)\n   \
          \         metadata_token_count = chunker.tokenizer.count_tokens(metadata_str)\n\
          \            metadata_obj[\"metadata_token_count\"] = metadata_token_count\n\
          \n            # Create a new chunk with embedding\n            new_chunk_with_embedding\
          \ = {\n                \"content\": raw_chunk,\n                \"mime_type\"\
          : \"text/markdown\",\n                \"embedding\": embedding,\n      \
          \          \"metadata\": metadata_obj,\n            }\n\n            print(f\"\
          New embedding: {new_chunk_with_embedding}\")\n\n            chunks_with_embeddings.append(new_chunk_with_embedding)\n\
          \n        return chunks_with_embeddings\n\n    def insert_chunks_with_embeddings_to_vector_db(\n\
          \        chunks_with_embeddings: List[Dict],\n        vector_db_id: str,\n\
          \        client: LlamaStackClient,\n    ) -> None:\n        if chunks_with_embeddings:\n\
          \            try:\n                client.vector_io.insert(\n          \
          \          vector_db_id=vector_db_id, chunks=chunks_with_embeddings\n  \
          \              )\n            except Exception as e:\n                _log.error(f\"\
          Failed to insert embeddings into vector database: {e}\")\n\n    def process_conversion_results(\n\
          \        conv_results: Iterator[ConversionResult], client: LlamaStackClient\n\
          \    ) -> None:\n        processed_docs = 0\n        embedding_model, chunker\
          \ = setup_chunker_and_embedder(\n            embed_model_id, max_tokens\n\
          \        )\n        for conv_res in conv_results:\n            if conv_res.status\
          \ != ConversionStatus.SUCCESS:\n                _log.warning(\n        \
          \            f\"Conversion failed for {conv_res.input.file.stem}: {conv_res.status}\"\
          \n                )\n                continue\n\n            processed_docs\
          \ += 1\n            file_name = conv_res.input.file.stem\n            document\
          \ = conv_res.document\n\n            if document is None:\n            \
          \    _log.warning(f\"Document conversion failed for {file_name}\")\n   \
          \             continue\n\n            chunks_with_embeddings = create_chunks_with_embeddings(\n\
          \                document, embedding_model, chunker, file_name\n       \
          \     )\n\n            insert_chunks_with_embeddings_to_vector_db(\n   \
          \             chunks_with_embeddings, vector_db_id, client\n           \
          \ )\n\n        _log.info(f\"Processed {processed_docs} documents successfully.\"\
          )\n\n    # Install ffmpeg before proceeding\n    install_ffmpeg()\n\n  \
          \  input_path = pathlib.Path(input_path)\n    output_path = pathlib.Path(output_path)\n\
          \    output_path.mkdir(parents=True, exist_ok=True)\n\n    input_audio_files\
          \ = [input_path / name for name in audio_split]\n\n    processed_audio_files,\
          \ temp_files_to_cleanup = convert_audio_to_wav(\n        input_audio_files\n\
          \    )\n\n    # Create Docling ASR converter\n    docling_asr_converter\
          \ = get_asr_converter()\n\n    # Convert all audio files to text\n    conv_results\
          \ = docling_asr_converter.convert_all(\n        processed_audio_files,\n\
          \        raises_on_error=True,\n    )\n\n    client = LlamaStackClient(base_url=service_url)\n\
          \n    process_conversion_results(conv_results, client)\n\n    cleanup_temp_files(temp_files_to_cleanup)\n\
          \n"
        image: quay.io/modh/odh-pipeline-runtime-pytorch-cuda-py311-ubi9@sha256:4706be608af3f33c88700ef6ef6a99e716fc95fc7d2e879502e81c0022fd840e
        resources:
          accelerator:
            count: '1'
            resourceCount: '1'
            resourceType: nvidia.com/gpu
            type: nvidia.com/gpu
          cpuLimit: 4.0
          cpuRequest: 0.5
          memoryLimit: 6.442450944
          memoryRequest: 2.147483648
          resourceCpuLimit: '4'
          resourceCpuRequest: 500m
          resourceMemoryLimit: 6Gi
          resourceMemoryRequest: 2Gi
    exec-docling-convert-and-ingest-audio-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - docling_convert_and_ingest_audio
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'docling' 'docling-core'\
          \ 'transformers' 'sentence-transformers' 'llama-stack' 'llama-stack-client'\
          \ 'pymilvus' 'fire' 'openai-whisper' 'torch' 'torchaudio' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef docling_convert_and_ingest_audio(\n    input_path: dsl.InputPath(\"\
          input-recordings\"),\n    audio_split: List[str],\n    output_path: dsl.OutputPath(\"\
          output-md\"),\n    embed_model_id: str,\n    max_tokens: int,\n    service_url:\
          \ str,\n    vector_db_id: str,\n):\n    import pathlib\n    import subprocess\n\
          \    import os\n\n    from docling.datamodel.pipeline_options_asr_model\
          \ import (\n        InlineAsrNativeWhisperOptions,\n        InferenceAsrFramework,\n\
          \    )\n\n    from docling.datamodel.base_models import ConversionStatus,\
          \ InputFormat\n    from docling.datamodel.document import ConversionResult\n\
          \    from docling.datamodel.pipeline_options import AsrPipelineOptions\n\
          \    from docling.document_converter import AudioFormatOption, DocumentConverter\n\
          \    from docling.pipeline.asr_pipeline import AsrPipeline\n    from docling_core.types.doc.document\
          \ import DoclingDocument\n\n    from transformers import AutoTokenizer\n\
          \    from sentence_transformers import SentenceTransformer\n    from docling_core.transforms.chunker.hybrid_chunker\
          \ import HybridChunker\n    import logging\n    from llama_stack_client\
          \ import LlamaStackClient\n    import uuid\n    import json\n\n    _log\
          \ = logging.getLogger(__name__)\n\n    # Install ffmpeg from https://ffmpeg.org/download.html#build-linux\n\
          \    def install_ffmpeg() -> None:\n        try:\n            # Check if\
          \ ffmpeg is already installed\n            subprocess.run([\"ffmpeg\", \"\
          -version\"], capture_output=True, check=True)\n            print(\"ffmpeg\
          \ is already installed\")\n            return\n        except (subprocess.CalledProcessError,\
          \ FileNotFoundError):\n            print(\"Installing ffmpeg...\")\n\n \
          \       try:\n\n            print(\"Package management restricted, downloading\
          \ static ffmpeg binary...\")\n\n            import urllib.request\n    \
          \        import stat\n            import pathlib\n            import shutil\n\
          \n            # Create temp directory\n            temp_dir = pathlib.Path(\"\
          /tmp/ffmpeg_install\")\n            temp_dir.mkdir(exist_ok=True)\n\n  \
          \          # Download static ffmpeg binary\n            ffmpeg_url = \"\
          https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz\"\
          \n            ffmpeg_archive = temp_dir / \"ffmpeg-static.tar.xz\"\n\n \
          \           print(f\"Downloading ffmpeg from {ffmpeg_url}\")\n         \
          \   urllib.request.urlretrieve(ffmpeg_url, ffmpeg_archive)\n\n         \
          \   print(\"Extracting ffmpeg archive...\")\n            subprocess.run(\n\
          \                [\"tar\", \"-xf\", str(ffmpeg_archive), \"-C\", str(temp_dir)],\n\
          \                check=True,\n                capture_output=True,\n   \
          \         )\n\n            ffmpeg_path_candidates = list(temp_dir.rglob(\"\
          ffmpeg\"))\n            if not ffmpeg_path_candidates:\n               \
          \ raise FileNotFoundError(\n                    \"Could not find 'ffmpeg'\
          \ executable in the extracted archive.\"\n                )\n\n        \
          \    ffmpeg_path = ffmpeg_path_candidates[0]\n\n            # Make executable\n\
          \            ffmpeg_path.chmod(\n                ffmpeg_path.stat().st_mode\
          \ | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH\n            )\n\n      \
          \      # Use a writable bin directory and add it to the PATH\n         \
          \   bin_dir = pathlib.Path(\"/tmp/bin\")\n            bin_dir.mkdir(exist_ok=True)\n\
          \            target_path = bin_dir / \"ffmpeg\"\n\n            # Move the\
          \ file to the target path\n            ffmpeg_path.rename(target_path)\n\
          \n            # Add to PATH environment variable\n            os.environ[\"\
          PATH\"] = f\"{str(bin_dir)}:{os.environ.get('PATH', '')}\"\n\n         \
          \   # Verify installation\n            subprocess.run(\n               \
          \ [str(target_path), \"-version\"], capture_output=True, check=True\n  \
          \          )\n            print(f\"Static ffmpeg binary installed to {target_path}\
          \ and added to PATH\")\n\n            # Clean up extraction directory\n\
          \            shutil.rmtree(temp_dir, ignore_errors=True)\n            return\n\
          \n        except Exception as e:\n            print(f\"Failed to install\
          \ ffmpeg: {e}\")\n            raise RuntimeError(\n                \"ffmpeg\
          \ installation failed. Audio processing requires ffmpeg.\"\n           \
          \ ) from e\n\n    # Convert audio files to WAV format that whisper can process\n\
          \    def convert_audio_to_wav(\n        input_audio_files: List[pathlib.Path],\n\
          \    ) -> Tuple[List[pathlib.Path], List[pathlib.Path]]:\n        processed_audio_files\
          \ = []\n        temp_files_to_cleanup = []\n\n        for audio_file in\
          \ input_audio_files:\n            if not audio_file.exists():\n        \
          \        print(f\"Skipping missing file: {audio_file}\")\n             \
          \   continue\n\n            # Check if file is already WAV\n           \
          \ if audio_file.suffix.lower() == \".wav\":\n                processed_audio_files.append(audio_file)\n\
          \                print(f\"Using WAV file directly: {audio_file.name}\")\n\
          \                continue\n\n            # Convert non-WAV files to WAV\
          \ format using ffmpeg\n            print(f\"Converting {audio_file.name}\
          \ to WAV format...\")\n            import tempfile\n\n            with tempfile.NamedTemporaryFile(\n\
          \                suffix=f\"_{audio_file.stem}.wav\", delete=False\n    \
          \        ) as tmp:\n                temp_wav = pathlib.Path(tmp.name)\n\n\
          \            try:\n                # Use ffmpeg to convert to WAV format\n\
          \                subprocess.run(\n                    [\n              \
          \          \"ffmpeg\",\n                        \"-i\",\n              \
          \          str(audio_file),\n                        \"-ar\",\n        \
          \                \"16000\",  # 16kHz sample rate (good for whisper)\n  \
          \                      \"-ac\",\n                        \"1\",  # mono\
          \ channel\n                        \"-c:a\",\n                        \"\
          pcm_s16le\",  # 16-bit PCM\n                        \"-y\",  # overwrite\
          \ output file\n                        str(temp_wav),\n                \
          \    ],\n                    check=True,\n                    capture_output=True,\n\
          \                )\n\n                processed_audio_files.append(temp_wav)\n\
          \                temp_files_to_cleanup.append(temp_wav)\n              \
          \  print(f\"Successfully converted {audio_file.name} to WAV format\")\n\n\
          \            except subprocess.CalledProcessError as e:\n              \
          \  print(f\"ffmpeg conversion failed for {audio_file.name}: {e}\")\n   \
          \             if e.stderr:\n                    print(f\"stderr: {e.stderr.decode()}\"\
          )\n                continue\n        return (processed_audio_files, temp_files_to_cleanup)\n\
          \n    # Clean up temporary files\n    def cleanup_temp_files(temp_files_to_cleanup:\
          \ List[pathlib.Path]) -> None:\n        for temp_file in temp_files_to_cleanup:\n\
          \            temp_file.unlink(missing_ok=True)\n            print(f\"Cleaned\
          \ up temporary file: {temp_file.name}\")\n\n    # Return a Docling DocumentConverter\
          \ configured for ASR with whisper_turbo model.\n    def get_asr_converter()\
          \ -> DocumentConverter:\n        \"\"\"Create a DocumentConverter configured\
          \ for ASR with whisper_turbo model.\"\"\"\n        whisper_turbo_asr_model\
          \ = InlineAsrNativeWhisperOptions(\n            repo_id=\"turbo\",\n   \
          \         inference_framework=InferenceAsrFramework.WHISPER,\n         \
          \   verbose=True,\n            timestamps=False,\n            word_timestamps=False,\n\
          \            temperature=0.0,\n            max_new_tokens=256,\n       \
          \     max_time_chunk=30.0,\n        )\n\n        pipeline_options = AsrPipelineOptions()\n\
          \        pipeline_options.asr_options = whisper_turbo_asr_model\n\n    \
          \    converter = DocumentConverter(\n            format_options={\n    \
          \            InputFormat.AUDIO: AudioFormatOption(\n                   \
          \ pipeline_cls=AsrPipeline,\n                    pipeline_options=pipeline_options,\n\
          \                )\n            }\n        )\n\n        return converter\n\
          \n    # ---- Embedding Helper functions ----\n    def setup_chunker_and_embedder(\n\
          \        embed_model_id: str, max_tokens: int\n    ) -> Tuple[SentenceTransformer,\
          \ HybridChunker]:\n        tokenizer = AutoTokenizer.from_pretrained(embed_model_id)\n\
          \        embedding_model = SentenceTransformer(embed_model_id)\n       \
          \ chunker = HybridChunker(\n            tokenizer=tokenizer, max_tokens=max_tokens,\
          \ merge_peers=True\n        )\n        return embedding_model, chunker\n\
          \n    def embed_text(text: str, embedding_model: SentenceTransformer) ->\
          \ list[float]:\n        return embedding_model.encode([text], normalize_embeddings=True).tolist()[0]\n\
          \n    def create_chunks_with_embeddings(\n        converted_data: DoclingDocument,\n\
          \        embedding_model: SentenceTransformer,\n        chunker: HybridChunker,\n\
          \        file_name: str,\n    ) -> List[Dict]:\n\n        chunks_with_embeddings\
          \ = []\n        for chunk in chunker.chunk(dl_doc=converted_data):\n   \
          \         raw_chunk = chunker.contextualize(chunk)\n            embedding\
          \ = embed_text(raw_chunk, embedding_model)\n            chunk_id = str(uuid.uuid4())\n\
          \            content_token_count = chunker.tokenizer.count_tokens(raw_chunk)\n\
          \n            # Prepare metadata object\n            metadata_obj = {\n\
          \                \"file_name\": file_name,\n                \"document_id\"\
          : chunk_id,\n                \"token_count\": content_token_count,\n   \
          \         }\n\n            metadata_str = json.dumps(metadata_obj)\n   \
          \         metadata_token_count = chunker.tokenizer.count_tokens(metadata_str)\n\
          \            metadata_obj[\"metadata_token_count\"] = metadata_token_count\n\
          \n            # Create a new chunk with embedding\n            new_chunk_with_embedding\
          \ = {\n                \"content\": raw_chunk,\n                \"mime_type\"\
          : \"text/markdown\",\n                \"embedding\": embedding,\n      \
          \          \"metadata\": metadata_obj,\n            }\n\n            print(f\"\
          New embedding: {new_chunk_with_embedding}\")\n\n            chunks_with_embeddings.append(new_chunk_with_embedding)\n\
          \n        return chunks_with_embeddings\n\n    def insert_chunks_with_embeddings_to_vector_db(\n\
          \        chunks_with_embeddings: List[Dict],\n        vector_db_id: str,\n\
          \        client: LlamaStackClient,\n    ) -> None:\n        if chunks_with_embeddings:\n\
          \            try:\n                client.vector_io.insert(\n          \
          \          vector_db_id=vector_db_id, chunks=chunks_with_embeddings\n  \
          \              )\n            except Exception as e:\n                _log.error(f\"\
          Failed to insert embeddings into vector database: {e}\")\n\n    def process_conversion_results(\n\
          \        conv_results: Iterator[ConversionResult], client: LlamaStackClient\n\
          \    ) -> None:\n        processed_docs = 0\n        embedding_model, chunker\
          \ = setup_chunker_and_embedder(\n            embed_model_id, max_tokens\n\
          \        )\n        for conv_res in conv_results:\n            if conv_res.status\
          \ != ConversionStatus.SUCCESS:\n                _log.warning(\n        \
          \            f\"Conversion failed for {conv_res.input.file.stem}: {conv_res.status}\"\
          \n                )\n                continue\n\n            processed_docs\
          \ += 1\n            file_name = conv_res.input.file.stem\n            document\
          \ = conv_res.document\n\n            if document is None:\n            \
          \    _log.warning(f\"Document conversion failed for {file_name}\")\n   \
          \             continue\n\n            chunks_with_embeddings = create_chunks_with_embeddings(\n\
          \                document, embedding_model, chunker, file_name\n       \
          \     )\n\n            insert_chunks_with_embeddings_to_vector_db(\n   \
          \             chunks_with_embeddings, vector_db_id, client\n           \
          \ )\n\n        _log.info(f\"Processed {processed_docs} documents successfully.\"\
          )\n\n    # Install ffmpeg before proceeding\n    install_ffmpeg()\n\n  \
          \  input_path = pathlib.Path(input_path)\n    output_path = pathlib.Path(output_path)\n\
          \    output_path.mkdir(parents=True, exist_ok=True)\n\n    input_audio_files\
          \ = [input_path / name for name in audio_split]\n\n    processed_audio_files,\
          \ temp_files_to_cleanup = convert_audio_to_wav(\n        input_audio_files\n\
          \    )\n\n    # Create Docling ASR converter\n    docling_asr_converter\
          \ = get_asr_converter()\n\n    # Convert all audio files to text\n    conv_results\
          \ = docling_asr_converter.convert_all(\n        processed_audio_files,\n\
          \        raises_on_error=True,\n    )\n\n    client = LlamaStackClient(base_url=service_url)\n\
          \n    process_conversion_results(conv_results, client)\n\n    cleanup_temp_files(temp_files_to_cleanup)\n\
          \n"
        image: quay.io/modh/odh-pipeline-runtime-pytorch-cuda-py311-ubi9@sha256:4706be608af3f33c88700ef6ef6a99e716fc95fc7d2e879502e81c0022fd840e
        resources:
          cpuLimit: 4.0
          cpuRequest: 0.5
          memoryLimit: 6.442450944
          memoryRequest: 2.147483648
          resourceCpuLimit: '4'
          resourceCpuRequest: 500m
          resourceMemoryLimit: 6Gi
          resourceMemoryRequest: 2Gi
    exec-import-audio-files:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - import_audio_files
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'requests' &&\
          \ \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef import_audio_files(\n    base_url: str,\n    audio_filenames:\
          \ str,\n    output_path: dsl.OutputPath(\"input-recordings\"),\n):\n   \
          \ import os\n    import requests\n    import shutil\n\n    os.makedirs(output_path,\
          \ exist_ok=True)\n    filenames = [f.strip() for f in audio_filenames.split(\"\
          ,\") if f.strip()]\n\n    for filename in filenames:\n        url = f\"\
          {base_url.rstrip('/')}/{filename}\"\n        file_path = os.path.join(output_path,\
          \ filename)\n\n        try:\n            with requests.get(url, stream=True,\
          \ timeout=30) as response:\n                response.raise_for_status()\n\
          \                with open(file_path, \"wb\") as f:\n                  \
          \  shutil.copyfileobj(response.raw, f)\n            print(f\"Downloaded\
          \ {filename}\")\n        except requests.exceptions.RequestException as\
          \ e:\n            print(f\"Failed to download {filename}: {e}, skipping.\"\
          )\n\n"
        image: registry.redhat.io/ubi9/python-312@sha256:e80ff3673c95b91f0dafdbe97afb261eab8244d7fd8b47e20ffcbcfee27fb168
    exec-register-vector-db:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - register_vector_db
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'llama-stack-client'\
          \ 'fire' 'requests' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef register_vector_db(\n    service_url: str,\n    vector_db_id:\
          \ str,\n    embed_model_id: str,\n):\n    from llama_stack_client import\
          \ LlamaStackClient\n\n    client = LlamaStackClient(base_url=service_url)\n\
          \n    models = client.models.list()\n    matching_model = next(\n      \
          \  (m for m in models if m.provider_resource_id == embed_model_id), None\n\
          \    )\n\n    if not matching_model:\n        raise ValueError(\n      \
          \      f\"Model with ID '{embed_model_id}' not found on LlamaStack server.\"\
          \n        )\n\n    if matching_model.model_type != \"embedding\":\n    \
          \    raise ValueError(f\"Model '{embed_model_id}' is not an embedding model\"\
          )\n\n    embedding_dimension = matching_model.metadata[\"embedding_dimension\"\
          ]\n\n    _ = client.vector_dbs.register(\n        vector_db_id=vector_db_id,\n\
          \        embedding_model=matching_model.identifier,\n        embedding_dimension=embedding_dimension,\n\
          \        provider_id=\"milvus\",\n    )\n    print(\n        f\"Registered\
          \ vector DB '{vector_db_id}' with embedding model '{embed_model_id}'.\"\n\
          \    )\n\n"
        image: registry.redhat.io/ubi9/python-312@sha256:e80ff3673c95b91f0dafdbe97afb261eab8244d7fd8b47e20ffcbcfee27fb168
pipelineInfo:
  description: Converts audio recordings to text using Docling ASR and generates embeddings
  name: docling-convert-pipeline
root:
  dag:
    tasks:
      create-audio-splits:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-create-audio-splits
        dependentTasks:
        - import-audio-files
        inputs:
          artifacts:
            input_path:
              taskOutputArtifact:
                outputArtifactKey: output_path
                producerTask: import-audio-files
          parameters:
            num_splits:
              componentInputParameter: num_workers
        taskInfo:
          name: create-audio-splits
      for-loop-1:
        componentRef:
          name: comp-for-loop-1
        dependentTasks:
        - create-audio-splits
        - import-audio-files
        inputs:
          artifacts:
            pipelinechannel--import-audio-files-output_path:
              taskOutputArtifact:
                outputArtifactKey: output_path
                producerTask: import-audio-files
          parameters:
            pipelinechannel--create-audio-splits-Output:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: create-audio-splits
            pipelinechannel--embed_model_id:
              componentInputParameter: embed_model_id
            pipelinechannel--max_tokens:
              componentInputParameter: max_tokens
            pipelinechannel--service_url:
              componentInputParameter: service_url
            pipelinechannel--use_gpu:
              componentInputParameter: use_gpu
            pipelinechannel--vector_db_id:
              componentInputParameter: vector_db_id
        parameterIterator:
          itemInput: pipelinechannel--create-audio-splits-Output-loop-item
          items:
            inputParameter: pipelinechannel--create-audio-splits-Output
        taskInfo:
          name: for-loop-1
      import-audio-files:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-import-audio-files
        inputs:
          parameters:
            audio_filenames:
              componentInputParameter: audio_filenames
            base_url:
              componentInputParameter: base_url
        taskInfo:
          name: import-audio-files
      register-vector-db:
        cachingOptions: {}
        componentRef:
          name: comp-register-vector-db
        inputs:
          parameters:
            embed_model_id:
              componentInputParameter: embed_model_id
            service_url:
              componentInputParameter: service_url
            vector_db_id:
              componentInputParameter: vector_db_id
        taskInfo:
          name: register-vector-db
  inputDefinitions:
    parameters:
      audio_filenames:
        defaultValue: RAG_use_cases.wav, RAG_customers.wav, RAG_benefits.m4a, RAG_vs_Regular_LLM_Output.m4a
        description: Comma-separated list of audio filenames to download and convert
        isOptional: true
        parameterType: STRING
      base_url:
        defaultValue: https://raw.githubusercontent.com/opendatahub-io/rag/main/demos/testing-data/audio-speech
        description: Base URL to fetch audio files
        isOptional: true
        parameterType: STRING
      embed_model_id:
        defaultValue: ibm-granite/granite-embedding-125m-english
        description: Model ID for embedding generation
        isOptional: true
        parameterType: STRING
      max_tokens:
        defaultValue: 512.0
        description: Maximum number of tokens per chunk
        isOptional: true
        parameterType: NUMBER_INTEGER
      num_workers:
        defaultValue: 1.0
        description: Number of docling worker pods to use
        isOptional: true
        parameterType: NUMBER_INTEGER
      service_url:
        defaultValue: http://lsd-llama-milvus-service:8321
        description: URL of the LlamaStack service
        isOptional: true
        parameterType: STRING
      use_gpu:
        defaultValue: true
        description: boolean to enable/disable gpu in the docling workers
        isOptional: true
        parameterType: BOOLEAN
      vector_db_id:
        defaultValue: asr-vector-db
        description: ID of the vector database to store embeddings
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.13.0
---
platforms:
  kubernetes:
    deploymentSpec:
      executors:
        exec-docling-convert-and-ingest-audio:
          nodeSelector:
            nodeSelectorJson:
              runtimeValue:
                constant: {}
          tolerations:
          - effect: NoSchedule
            key: nvidia.com/gpu
            operator: Exists
